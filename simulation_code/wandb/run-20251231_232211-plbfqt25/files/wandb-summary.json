{"training/clip_fraction":1,"_step":3415,"loss/policy":0.1623758441872066,"training/sigma_max":0.16,"loss/entropy":0,"_timestamp":1.7672547663379977e+09,"episodes_total":6832,"training/value_mean":-90.3380355834961,"batch":3416,"training/learning_rate":3.828112618806438e-06,"_runtime":13436,"reward/batch_avg":-76.59089507351715,"time/batch_seconds":3.934149980545044,"reward/batch_min":-77.33933196715684,"_wandb":{"runtime":13436},"training/advantage_mean":0,"reward/batch_max":-75.84245817987747,"training/effective_batch_size":120,"training/sigma_min":0.08,"training/kl_divergence":5.390725930805143e+07,"loss/critic":220.08634440104166}