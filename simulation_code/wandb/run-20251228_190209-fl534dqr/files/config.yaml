_wandb:
    value:
        cli_version: 0.23.1
        e:
            6tmvjzbeizi5wb8wp2jptbwt4wtybsiw:
                apple:
                    ecpuCores: 2
                    gpuCores: 14
                    memoryGb: 16
                    name: Apple M1 Pro
                    pcpuCores: 6
                    ramTotalBytes: "17179869184"
                    swapTotalBytes: "22548578304"
                args:
                    - --no-render
                    - --headless
                codePath: simulation_code/train_reinflow.py
                codePathLocal: train_reinflow.py
                cpu_count: 8
                cpu_count_logical: 8
                disk:
                    /:
                        total: "494384795648"
                        used: "435473965056"
                email: 7adamyasingh@gmail.com
                executable: /opt/homebrew/anaconda3/envs/lerobot/bin/python
                git:
                    commit: 96056067b5d19e456ef9711519fbe6d61c1f5bd7
                    remote: https://github.com/adamya-singh/SO-ARM-101.git
                host: macbookpro.lan
                memory:
                    total: "17179869184"
                os: macOS-15.5-arm64-arm-64bit
                program: /Users/adamyasingh/dev/SO-ARM-101/mujoco/SO-ARM-101/simulation_code/train_reinflow.py
                python: CPython 3.10.18
                root: /Users/adamyasingh/dev/SO-ARM-101/mujoco/SO-ARM-101/simulation_code
                startedAt: "2025-12-29T00:02:09.961753Z"
                writerId: 6tmvjzbeizi5wb8wp2jptbwt4wtybsiw
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
            "2":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
            "3":
                - 2
                - 16
            "4": 3.10.18
            "5": 0.23.1
            "6": 4.57.3
            "12": 0.23.1
            "13": darwin-arm64
chunks_per_episode:
    value: 3
clip_epsilon:
    value: 0.01
critic_lr:
    value: 0.0001
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
minibatch_size:
    value: 8
num_denoising_steps:
    value: 4
num_ppo_epochs:
    value: 4
policy_lr:
    value: 3e-05
target_kl:
    value: 1
train_action_head:
    value: true
train_critic:
    value: true
train_full_expert:
    value: true
train_noise_head:
    value: true
train_time_mlp:
    value: true
training_mode:
    value: ppo-on-policy
