{"training/kl_divergence":3.1348915100097656,"loss/policy":1.9487605094909668,"training/sigma_max":0.16,"reward/batch_max":-46.318727751683596,"training/learning_rate":2.9575872675236514e-06,"reward/batch_min":-55.306764326872035,"batch":120,"training/advantage_mean":-3.973643103449831e-08,"training/clip_fraction":1,"loss/critic":95.77660369873047,"_timestamp":1.7669736644427865e+09,"episodes_total":240,"time/batch_seconds":3.8144280910491943,"reward/batch_avg":-50.81274603927781,"_step":119,"loss/entropy":-194.89418029785156,"training/sigma_min":0.08,"_wandb":{"runtime":454},"_runtime":454,"training/value_mean":-53.24749755859375}