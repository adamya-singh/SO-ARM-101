{"loss/entropy":-191.88421630859375,"loss/policy":1.9353166421254475,"_runtime":94,"loss/critic":84.5301284790039,"training/advantage_mean":3.973643103449831e-08,"training/kl_divergence":0.1608896553516388,"_timestamp":1.7669765887377322e+09,"training/value_mean":-27.848289489746094,"reward/avg":-42.211075925782545,"_step":2,"training/learning_rate":2.9999933380225085e-07,"time/episode_seconds":28.71288299560547,"training/clip_fraction":1,"training/sigma_max":0.16,"training/sigma_min":0.08,"_wandb":{"runtime":94},"episode":3,"reward/episode":-42.47516233354648}